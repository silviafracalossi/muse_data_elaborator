{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muse Data Elaborator\n",
    "\n",
    "#### TODO:\n",
    "1. Data Recording\n",
    "    1. (done) Choose the App\n",
    "    1. (done) Download the data\n",
    "1. Data Cleaning\n",
    "    1. (done) Remove noise\n",
    "    1. (done) Remove invalid parts: sensor does not work -> remove that line\n",
    "1. Feature Extraction\n",
    "    1. (done) Calculation of features (five brain wave frequency bands)\n",
    "    1. (done) Normalize data using the baseline.\n",
    "1. \"Machine Learning\"\n",
    "    1. (done) Split data. (window of 30 seconds, taking a sample from it)\n",
    "    1. (done) Calculate the stress level.\n",
    "    1. (done) Label data.\n",
    "1. Data Visualization\n",
    "    1. (done) Sections visualization.\n",
    "    1. Scenarios comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "##### Waves information\n",
    "1. Alpha:\n",
    "    - increases when a person is relaxed (the lower the busier)\n",
    "    - blocked in task engagement\n",
    "    \n",
    "    \n",
    "1. Beta:\n",
    "    - increases in task engagement\n",
    "    \n",
    "    \n",
    "1. Theta:\n",
    "    - increases in demand and working memory load\n",
    "    - sensitive to data difficulty\n",
    "    - suppressed in task engagement\n",
    "    \n",
    "    \n",
    "1. Delta:\n",
    "    - sensitive to data difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show, output_file, save, curdoc\n",
    "from bokeh.models import ColumnDataSource, HoverTool, NumeralTickFormatter, Title\n",
    "from bokeh.models.widgets import Select\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from datetime import datetime as dt\n",
    "from math import pi, sqrt\n",
    "import os\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "# Scenarios Titles\n",
    "experiment_labels = ['scenario 1', 'scenario 2', 'scenario 3']\n",
    "all_scenario_labels = ['fishes 1', 'scenario 1', 'fishes 2', 'scenario 2', 'fishes 3', 'scenario 3']\n",
    "\n",
    "# Ranges for plots\n",
    "min_range = 200\n",
    "max_range = -100\n",
    "\n",
    "# Setting the threshold to have a good sensors signal - 4 HSI possible values: 1=Good, 2=Medium, 4=Bad\n",
    "hsi_threshold = 8\n",
    "windows_no = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Calls all the algorithms in the right order\n",
    "def execute_class(participant_no, experiment_order):\n",
    "    \n",
    "    # Read the file\n",
    "    df = read_file(participant_no)\n",
    "    \n",
    "    # Clean the data and split it based on content\n",
    "    df_records, df_elements, df_markers = clean_data(df)\n",
    "\n",
    "    # Checking if the data returned is valid\n",
    "    if str(type(df_records)) != \"<class 'str'>\":\n",
    "        \n",
    "        # Calculating the frequencies using the correct range\n",
    "        df_prepared = extract_features(df_records)\n",
    "        #visualize_simple_plot([df_prepared], \"initial\", ['All'])\n",
    "        \n",
    "        # Split the data into baseline data and experiment data\n",
    "        sections = split_data(df_prepared, df_markers)\n",
    "        #visualize_simple_plot(sections, \"sections\", all_scenario_labels)\n",
    "        \n",
    "        # Normalize the experiment based on its baseline and the quality of data\n",
    "        normalized_sections = normalize_data(sections)\n",
    "        \n",
    "        # Splitting data into comparable windows\n",
    "        window_stress_values = split_in_windows(normalized_sections, windows_no)\n",
    "        \n",
    "        # Save file in CSV\n",
    "        save_sections(participant_no, window_stress_values, experiment_order)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dato into dataframe\n",
    "def read_file(participant_no):\n",
    "    __file__ = participant_no + '.csv'\n",
    "    my_absolute_dirpath = os.path.abspath(os.path.dirname(__file__))\n",
    "    file_path = my_absolute_dirpath+\"\\\\aData\\\\\"+__file__\n",
    "    df = pd.read_csv(file_path, sep=\",\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removes useless columns and checks the correctness\n",
    "def clean_data(df):\n",
    "    \n",
    "    # Removing useless columns and formatting\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'], errors='coerce')\n",
    "    df_cleaned = df.drop(columns=['Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z', 'AUX_RIGHT', 'Battery'])\n",
    "\n",
    "    # Extracting the markers from the dataframe\n",
    "    df_markers = df_cleaned[df_cleaned['Elements'].str.contains('/Marker/', na=False)]\n",
    "    df_markers = df_markers.reset_index(drop=True)\n",
    "    df_markers = df_markers[['TimeStamp', 'Elements']]\n",
    "    \n",
    "    # Checking if the markers are correct - Markers are 7: 1x \"marker 5\", 3x \"marker 1\", 3x \"marker 2\"\n",
    "    markers_no = df_markers.shape[0]\n",
    "    marker_five_no = df_markers[df_markers['Elements'] == '/Marker/5'].shape[0]\n",
    "    marker_one_no = df_markers[df_markers['Elements'] == '/Marker/1'].shape[0]\n",
    "    marker_two_no = df_markers[df_markers['Elements'] == '/Marker/2'].shape[0]\n",
    "    if not (markers_no == 7 and marker_five_no == 1 and marker_one_no == 3 and marker_two_no == 3):\n",
    "        print(\"Markers are not of the desired number or type\")\n",
    "        print(\"Marker 5: \" +str(marker_five_no))\n",
    "        print(\"Marker 2: \" +str(marker_two_no))\n",
    "        print(\"Marker 1: \" +str(marker_one_no))\n",
    "        print(\"Total Markers: \"+str(markers_no))\n",
    "        return '', '', ''\n",
    "    \n",
    "    # Deleting all records before the initial marker timestamp (time spent positioning the sensor)\n",
    "    df_start_markers = df_markers[df_markers['Elements'] == '/Marker/5']\n",
    "    timestamp_start = df_start_markers['TimeStamp'].iloc[-1]\n",
    "    df_formatted = df_cleaned[df_cleaned['TimeStamp'] >= timestamp_start]\n",
    "    \n",
    "    # Removing marker 5 from all dataframes\n",
    "    df_markers = df_markers.iloc[1:]\n",
    "    df_formatted = df_formatted.iloc[1:]\n",
    "\n",
    "    # Extracting the elements - markers, blinks, clinches\n",
    "    df_elements = df_formatted[df_formatted['Elements'].str.contains('/', na=False)]\n",
    "    df_elements = df_elements[['TimeStamp', 'Elements']]\n",
    "    df_elements = df_elements.dropna()\n",
    "    df_elements = df_elements.reset_index(drop=True)\n",
    "\n",
    "    # Extracting the records with the HeadBandOn\n",
    "    df_records_headbandon = df_formatted[df_formatted['HeadBandOn'] == 1]\n",
    "    df_records_headbandon = df_records_headbandon.drop(columns=['Elements'])\n",
    "    df_records_headbandon = df_records_headbandon.reset_index(drop=True)\n",
    "    \n",
    "    # Removing low quality data\n",
    "    df_records_headbandon['Sensor_Quality'] = df_records_headbandon['HSI_TP9'] + df_records_headbandon['HSI_AF7'] + df_records_headbandon['HSI_AF8'] + df_records_headbandon['HSI_TP10']\n",
    "    df_records = df_records_headbandon[df_records_headbandon['Sensor_Quality'] <= hsi_threshold]\n",
    "    \n",
    "    # Defining and printing low quality data proportion\n",
    "    lines = df_records_headbandon.shape[0]\n",
    "    usable_lines = df_records.shape[0]\n",
    "    print(str(usable_lines) + \"/\" + str(lines) + \" usable lines \")\n",
    "    print(\"Total usable lines for this participant is \"+\n",
    "          ('%.2f' % (100*usable_lines/lines,)).rstrip('0').rstrip('.')+\n",
    "          \"% - threshold: \"+str(hsi_threshold))\n",
    "    print()\n",
    "    \n",
    "    return df_records, df_elements, df_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transforming and extracting data, including data split and normalization\n",
    "def extract_features(df_records):\n",
    "    \n",
    "    # Settings to change the data range\n",
    "    old_range_max = 3\n",
    "    old_range_min = -3\n",
    "    old_range = (old_range_max - old_range_min) \n",
    "    new_range_max = 200\n",
    "    new_range_min = -100\n",
    "    new_range = (new_range_max - new_range_min)\n",
    "\n",
    "    # Calculating Average Absolute Brain Waves\n",
    "    df_avg_bw = df_records.drop(columns=['Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10', 'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10', 'Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10', 'Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8', 'Gamma_TP10'])\n",
    "    old_alpha_value = (df_records['Alpha_TP9'] + df_records['Alpha_AF7'] + df_records['Alpha_AF8'] + df_records['Alpha_TP10'])/4\n",
    "    old_beta_value = (df_records['Beta_TP9'] + df_records['Beta_AF7'] + df_records['Beta_AF8'] + df_records['Beta_TP10'])/4\n",
    "    old_delta_value = (df_records['Delta_TP9'] + df_records['Delta_AF7'] + df_records['Delta_AF8'] + df_records['Delta_TP10'])/4\n",
    "    old_gamma_value = (df_records['Gamma_TP9'] + df_records['Gamma_AF7'] + df_records['Gamma_AF8'] + df_records['Gamma_TP10'])/4\n",
    "    old_theta_value = (df_records['Theta_TP9'] + df_records['Theta_AF7'] + df_records['Theta_AF8'] + df_records['Theta_TP10'])/4\n",
    "\n",
    "    # Converting in new range\n",
    "    df_avg_bw['Alpha_Avg'] = (((old_alpha_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Beta_Avg'] = (((old_beta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Delta_Avg'] = (((old_delta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Gamma_Avg'] = (((old_gamma_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Theta_Avg'] = (((old_theta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    \n",
    "    # Calculating first ratio: Beta / (Alpha + Theta) --> task difficulty indicator + task engagement\n",
    "    df_avg_bw['First_Ratio'] = df_avg_bw['Beta_Avg'] / (df_avg_bw['Alpha_Avg'] + df_avg_bw['Theta_Avg'])\n",
    "        \n",
    "    # Calculating second ratio: Theta / (Alpha + Beta) --> task difficulty indicator\n",
    "    df_avg_bw['Second_Ratio'] = df_avg_bw['Theta_Avg'] / (df_avg_bw['Alpha_Avg'] + df_avg_bw['Beta_Avg'])\n",
    "    \n",
    "    # Calculating stress level\n",
    "    df_avg_bw['Stress_Level'] = df_avg_bw['First_Ratio'] + df_avg_bw['Second_Ratio']\n",
    "\n",
    "    return df_avg_bw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Splitting data based on markers\n",
    "def split_data(df, df_markers):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    sections = []\n",
    "    \n",
    "    # Splitting the data and visualizing them separately\n",
    "    prev_timestamp = \"null\"\n",
    "    markers_timestamps = df_markers['TimeStamp'].tolist()\n",
    "    for timestamp in markers_timestamps:\n",
    "        \n",
    "        # Taking different actions for the dataframe splitting\n",
    "        if prev_timestamp != \"null\":\n",
    "            section = df[\n",
    "                df['TimeStamp'] > prev_timestamp\n",
    "            ]\n",
    "            section = section[\n",
    "                section['TimeStamp'] <= timestamp\n",
    "            ]\n",
    "            \n",
    "            sections.append(section)\n",
    "            i=i+1\n",
    "            \n",
    "        prev_timestamp = timestamp\n",
    "\n",
    "    # Visualizing the last part of the experiment\n",
    "    section = df[\n",
    "        df['TimeStamp'] > prev_timestamp\n",
    "    ]\n",
    "    sections.append(section)\n",
    "    \n",
    "    # Returns 6 sections: (baseline + scenario) x3\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Normalizing the data based on the baseline\n",
    "def normalize_data(sections):\n",
    "    \n",
    "    # Declaring variables for the method execution\n",
    "    h = 0\n",
    "    total_lines = 0\n",
    "    total_usable_lines = 0\n",
    "    frequency_columns = ['Alpha_Avg', 'Beta_Avg', 'Delta_Avg', 'Gamma_Avg', 'Theta_Avg']\n",
    "    new_sections = []\n",
    "    \n",
    "    # Iterating through the 3 baseline-experiment sections\n",
    "    for i in range(0,6,2):\n",
    "            \n",
    "        # Defining variables for execution\n",
    "        df_baseline = sections[i]\n",
    "        df_experiment = sections[i+1]\n",
    "        \n",
    "        # Extracting the last minute of recording \n",
    "        baseline_last_timestamp = df_baseline.iloc[-1]['TimeStamp']\n",
    "        baseline_start = baseline_last_timestamp - pd.Timedelta(minutes=1)\n",
    "        df_baseline_min = df_baseline[df_baseline['TimeStamp'] >= baseline_start]\n",
    "        \n",
    "        # Storing the mean of the baseline\n",
    "        baseline_frequencies = []\n",
    "        print(\"Frequency Mean of baseline \" +str(h)+\":\")\n",
    "        for j in range(0,5):\n",
    "            baseline_frequencies.append(df_baseline_min[frequency_columns[j]].mean())\n",
    "            print(\"-- \" + frequency_columns[j] + \": \" +('%.2f' % (baseline_frequencies[j],)).rstrip('0').rstrip('.'))\n",
    "        print()\n",
    "                \n",
    "        # Subtracting baseline from data\n",
    "        for column in ['First_Ratio', 'Second_Ratio', 'Stress_Level']:\n",
    "            baseline_avg = df_baseline_min[column].mean()\n",
    "            df_experiment[column] = df_experiment[column] - baseline_avg\n",
    "                \n",
    "        # Storing the elaborated sections\n",
    "        new_sections.append(df_experiment)\n",
    "        h = h + 1\n",
    "        \n",
    "    return new_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create windows\n",
    "def split_in_windows(sections, k):\n",
    "    \n",
    "    # Defining return value - for each section, one array containing first_ratio.mean, second_ratio.mean, stress_level.mean\n",
    "    all_section_means = []\n",
    "    \n",
    "    # Accessing every scenario\n",
    "    for section in sections:\n",
    "        \n",
    "        # Defining array useful for the execution\n",
    "        mean_values = []\n",
    "        first_ratio = []\n",
    "        second_ratio = []\n",
    "        stress_level = []\n",
    "        \n",
    "        # Copying the section to better manage it\n",
    "        new_section = section.copy()\n",
    "        \n",
    "        # Iterate while we still have data after all the 30 seconds steps\n",
    "        while not new_section.empty:\n",
    "            \n",
    "            # Retrieving a new row\n",
    "            row = new_section.iloc[0]\n",
    "            timestamp = row['TimeStamp'] + pd.Timedelta(seconds=k)\n",
    "            \n",
    "            # Storing the samples\n",
    "            first_ratio.append(row['First_Ratio'])\n",
    "            second_ratio.append(row['Second_Ratio'])\n",
    "            stress_level.append(row['Stress_Level'])\n",
    "            \n",
    "            # Excluding the 30 seconds just analyzed\n",
    "            new_section = new_section[new_section['TimeStamp'] >= timestamp]\n",
    "\n",
    "        # Appending the mean values\n",
    "        mean_values.append(statistics.mean(first_ratio))\n",
    "        mean_values.append(statistics.mean(second_ratio))\n",
    "        mean_values.append(statistics.mean(stress_level))\n",
    "        \n",
    "        # Printing the results\n",
    "        print(\"Mean values for First_Ratio, Second_Ratio, Stress_Level\")\n",
    "        print(mean_values)\n",
    "        \n",
    "        # Appending the result in a return object\n",
    "        all_section_means.append(mean_values)\n",
    "        \n",
    "    return all_section_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END: Visualizing the data for the given simple sections\n",
    "def visualize_simple_plot(sections, extra_title, labels):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    \n",
    "    # Visualizing all the sections\n",
    "    for section in sections:\n",
    "        \n",
    "        # Defining variables used in method\n",
    "        df = section\n",
    "        title = labels[i]\n",
    "        \n",
    "        # Saving data in ColumnDataSource\n",
    "        data = {'TimeStamp': np.array(df['TimeStamp'], dtype='i8').view('datetime64[ms]').tolist(),\n",
    "                'Alpha': list(df['Alpha_Avg']),\n",
    "                'Beta': list(df['Beta_Avg']),\n",
    "                'Delta': list(df['Delta_Avg']),\n",
    "                'Gamma': list(df['Gamma_Avg']), \n",
    "                'Theta': list(df['Theta_Avg']),\n",
    "                'TimeStamp_tooltip': [x.strftime(\"%Y-%m-%d %H:%M:%S\") for x in df['TimeStamp']]\n",
    "                }\n",
    "        source = ColumnDataSource(data=data)\n",
    "\n",
    "        # Calculating the graph ranges\n",
    "        smallest = min_range\n",
    "        largest = max_range\n",
    "        smallest -= 5\n",
    "        largest += 5\n",
    "\n",
    "        # Plotting the data\n",
    "        p = figure(x_range=(min(data['TimeStamp']), max(data['TimeStamp'])), y_range=(smallest, largest), plot_width=1500, plot_height=600, title=extra_title+\": Plot of \"+title)\n",
    "        p.line(x='TimeStamp', y='Alpha', source=source, color=\"#3DB3FE\", line_width=2, legend=dict(value=\"Alpha\"))\n",
    "        p.line(x='TimeStamp', y='Beta', source=source, color=\"#38A967\", line_width=2, legend=dict(value=\"Beta\"))\n",
    "        p.line(x='TimeStamp', y='Delta', source=source, color=\"#C93030\", line_width=2, legend=dict(value=\"Delta\"))\n",
    "        p.line(x='TimeStamp', y='Gamma', source=source, color=\"#F1A219\", line_width=2, legend=dict(value=\"Gamma\"))\n",
    "        p.line(x='TimeStamp', y='Theta', source=source, color=\"#A822F3\", line_width=2, legend=dict(value=\"Theta\"))\n",
    "\n",
    "        # Adding hover and other visualization tools\n",
    "        hover = HoverTool()\n",
    "        hover.tooltips=[\n",
    "            (\"Value\", \"$y\"),\n",
    "            (\"Timestamp\", \"@TimeStamp_tooltip\")\n",
    "        ]\n",
    "        p.add_tools(hover)\n",
    "        p.add_layout(Title(text=\"TimeStamp\", align=\"center\"), \"below\")\n",
    "        p.add_layout(Title(text=\"Frequency\", align=\"center\"), \"left\")\n",
    "        p.xaxis.major_label_orientation = np.pi / 4\n",
    "        p.legend.location = 'top_right'\n",
    "        \n",
    "        show(p)\n",
    "        i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sections(participant_no, mean_stress_values, experiment_order): \n",
    "    \n",
    "    # Defining header\n",
    "    header = [\"First_Ratio\", \"Second_Ratio\", \"Stress_Level\"]\n",
    "    \n",
    "    # Iterating through the sections    \n",
    "    for i in range(0, 3):       \n",
    "        \n",
    "        # Creating the name of the file\n",
    "        file_name = 'aResults/results_'+experiment_order[i]+'_'+participant_no+'.csv'\n",
    "\n",
    "        # Writing on the CSV\n",
    "        with open(file_name, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            writer.writerow(mean_stress_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Participant 01 ====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'execute_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3d2bccf6fe7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"==== Participant \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" ====\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mexecute_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiments_order\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'execute_class' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------Main Method-------------------------------------------\n",
    "\n",
    "# TODO change it so that the algorithm takes this as input\n",
    "# Experiment order: R=Rational, S=StringUtil, U=UtilObject\n",
    "\n",
    "'''\n",
    "participants = ['03']\n",
    "experiments_order = [\n",
    "    ['S', 'U', 'R']\n",
    "]\n",
    "\n",
    "participants = ['01']\n",
    "experiments_order = [\n",
    "    ['R', 'S', 'U']\n",
    "]\n",
    "\n",
    "# experiment 5 = ['U', 'R', 'S']\n",
    "\n",
    "'''\n",
    "\n",
    "participants = ['01', '02', '03', '04']\n",
    "experiments_order = [\n",
    "    ['R', 'S', 'U'],\n",
    "    ['U', 'R', 'S'],\n",
    "    ['S', 'U', 'R'],\n",
    "    ['R', 'S', 'U']\n",
    "]\n",
    "\n",
    "# Sampling every 30 seconds and then do the average\n",
    "\n",
    "for i in range(0, len(participants)):\n",
    "    print(\"==== Participant \"+participants[i]+\" ====\")\n",
    "    execute_class(participants[i], experiments_order[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
