{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muse Data Elaborator\n",
    "\n",
    "#### TODO:\n",
    "1. (done) Data Recording\n",
    "    1. (done) Choose the App\n",
    "    1. (done) Download the data\n",
    "1. Data Cleaning\n",
    "    1. (done) Remove noise\n",
    "    1. Remove invalid parts: sensor does not work -> remove that line\n",
    "1. Feature Extraction\n",
    "    1. (done) Calculation of features (five brain wave frequency bands)\n",
    "    1. (done) Normalize data using the baseline.\n",
    "1. \"Machine Learning\"\n",
    "    1. Split data. (window of even 2 seconds; 5-60 seconds)\n",
    "    1. Calculate the stress level.\n",
    "    1. Label data.\n",
    "1. (done) Data Visualization\n",
    "\n",
    "#### TODO from notes:\n",
    "1. windows of 10 seconds each; mean of the values\n",
    "1. scenario ranking per participant (stress level)\n",
    "1. sum the number of blinks and jaws, in experiment and in baseline\n",
    "1. scenario ranking per participant (blinks and jaws)\n",
    "\n",
    "1. restructure all the texts in the correct way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "##### Waves information\n",
    "1. Alpha:\n",
    "    - increases when a person is relaxed (the lower the busier)\n",
    "    - blocked in task engagement\n",
    "    \n",
    "    \n",
    "1. Beta:\n",
    "    - increases in task engagement\n",
    "    \n",
    "    \n",
    "1. Theta:\n",
    "    - increases in demand and working memory load\n",
    "    - sensitive to data difficulty\n",
    "    - suppressed in task engagement\n",
    "    \n",
    "    \n",
    "1. Delta:\n",
    "    - sensitive to data difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show, output_file, save, curdoc\n",
    "from bokeh.models import ColumnDataSource, HoverTool, NumeralTickFormatter, Title\n",
    "from bokeh.models.widgets import Select\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from datetime import datetime as dt\n",
    "from math import pi, sqrt\n",
    "import os\n",
    "\n",
    "# Scenarios Titles\n",
    "experiment_labels = ['scenario 1', 'scenario 2', 'scenario 3']\n",
    "all_scenario_labels = ['fishes 1', 'scenario 1', 'fishes 2', 'scenario 2', 'fishes 3', 'scenario 3']\n",
    "\n",
    "# Ranges for plots\n",
    "min_range = 200\n",
    "max_range = -100\n",
    "\n",
    "# Setting the threshold to have a good sensors signal - 4 HSI possible values: 1=Good, 2=Medium, 4=Bad\n",
    "hsi_threshold = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Calls all the algorithms in the right order\n",
    "def execute_class(participant_no):\n",
    "    \n",
    "    # Read the file\n",
    "    df = read_file(participant_no)\n",
    "    \n",
    "    # Clean the data and split it based on content\n",
    "    df_records, df_elements, df_markers = clean_data(df)\n",
    "\n",
    "    # Checking if the data returned is valid\n",
    "    if str(type(df_records)) != \"<class 'str'>\":\n",
    "        \n",
    "        # Calculating the frequencies using the correct range\n",
    "        df_prepared = extract_features(df_records)\n",
    "        #visualize_simple_plot([df_prepared], \"initial\", ['All'])\n",
    "        \n",
    "        # Split the data into baseline data and experiment data\n",
    "        sections = split_data(df_prepared, df_markers)\n",
    "        #visualize_simple_plot(sections, \"sections\", all_scenario_labels)\n",
    "        \n",
    "        # Normalize the experiment based on its baseline and the quality of data\n",
    "        normalized_sections = normalize_data(sections)\n",
    "        #visualize_simple_plot(normalized_sections, \"after_baseline_quality\", experiment_labels)\n",
    "        visualize_complex_plot(normalized_sections, \"stress_sections\", experiment_labels)\n",
    "        \n",
    "        # Splitting data into comparable windows\n",
    "        window_sections = split_in_windows(normalized_sections)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dato into dataframe\n",
    "def read_file(participant_no):\n",
    "    __file__ = participant_no + '.csv'\n",
    "    my_absolute_dirpath = os.path.abspath(os.path.dirname(__file__))\n",
    "    file_path = my_absolute_dirpath+\"\\\\aData\\\\\"+__file__\n",
    "    df = pd.read_csv(file_path, sep=\",\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removes useless columns and checks the correctness\n",
    "def clean_data(df):\n",
    "    \n",
    "    # Removing useless columns and formatting\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'], errors='coerce')\n",
    "    df_cleaned = df.drop(columns=['Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z', 'AUX_RIGHT', 'Battery'])\n",
    "\n",
    "    # Extracting the markers from the dataframe\n",
    "    df_markers = df_cleaned[df_cleaned['Elements'].str.contains('/Marker/', na=False)]\n",
    "    df_markers = df_markers.reset_index(drop=True)\n",
    "    df_markers = df_markers[['TimeStamp', 'Elements']]\n",
    "    \n",
    "    # Checking if the markers are correct - Markers are 7: 1x \"marker 5\", 3x \"marker 1\", 3x \"marker 2\"\n",
    "    markers_no = df_markers.shape[0]\n",
    "    marker_five_no = df_markers[df_markers['Elements'] == '/Marker/5'].shape[0]\n",
    "    marker_one_no = df_markers[df_markers['Elements'] == '/Marker/1'].shape[0]\n",
    "    marker_two_no = df_markers[df_markers['Elements'] == '/Marker/2'].shape[0]\n",
    "    if not (markers_no == 7 and marker_five_no == 1 and marker_one_no == 3 and marker_two_no == 3):\n",
    "        print(\"Markers are not of the desired number or type\")\n",
    "        print(\"Marker 5: \" +str(marker_five_no))\n",
    "        print(\"Marker 2: \" +str(marker_two_no))\n",
    "        print(\"Marker 1: \" +str(marker_one_no))\n",
    "        print(\"Total Markers: \"+str(markers_no))\n",
    "        return '', '', ''\n",
    "    \n",
    "    # Deleting all records before the initial marker timestamp (time spent positioning the sensor)\n",
    "    df_start_markers = df_markers[df_markers['Elements'] == '/Marker/5']\n",
    "    timestamp_start = df_start_markers['TimeStamp'].iloc[-1]\n",
    "    df_formatted = df_cleaned[df_cleaned['TimeStamp'] >= timestamp_start]\n",
    "    \n",
    "    # Removing marker 5 from all dataframes\n",
    "    df_markers = df_markers.iloc[1:]\n",
    "    df_formatted = df_formatted.iloc[1:]\n",
    "\n",
    "    # Extracting the elements - markers, blinks, clinches\n",
    "    df_elements = df_formatted[df_formatted['Elements'].str.contains('/', na=False)]\n",
    "    df_elements = df_elements[['TimeStamp', 'Elements']]\n",
    "    df_elements = df_elements.dropna()\n",
    "    df_elements = df_elements.reset_index(drop=True)\n",
    "\n",
    "    # Extracting the records with the HeadBandOn\n",
    "    df_records_headbandon = df_formatted[df_formatted['HeadBandOn'] == 1]\n",
    "    df_records_headbandon = df_records_headbandon.drop(columns=['Elements'])\n",
    "    df_records_headbandon = df_records_headbandon.reset_index(drop=True)\n",
    "    \n",
    "    # Removing low quality data\n",
    "    df_records_headbandon['Sensor_Quality'] = df_records_headbandon['HSI_TP9'] + df_records_headbandon['HSI_AF7'] + df_records_headbandon['HSI_AF8'] + df_records_headbandon['HSI_TP10']\n",
    "    df_records = df_records_headbandon[df_records_headbandon['Sensor_Quality'] <= hsi_threshold]\n",
    "    \n",
    "    # Defining and printing low quality data proportion\n",
    "    lines = df_records_headbandon.shape[0]\n",
    "    usable_lines = df_records.shape[0]\n",
    "    print(str(usable_lines) + \"/\" + str(lines) + \" usable lines \")\n",
    "    print(\"Total usable lines for this participant is \"+\n",
    "          ('%.2f' % (100*usable_lines/lines,)).rstrip('0').rstrip('.')+\n",
    "          \"% - threshold: \"+str(hsi_threshold))\n",
    "    print()\n",
    "    \n",
    "    return df_records, df_elements, df_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transforming and extracting data, including data split and normalization\n",
    "def extract_features(df_records):\n",
    "    \n",
    "    # Settings to change the data range\n",
    "    old_range_max = 3\n",
    "    old_range_min = -3\n",
    "    old_range = (old_range_max - old_range_min) \n",
    "    new_range_max = 200\n",
    "    new_range_min = -100\n",
    "    new_range = (new_range_max - new_range_min)\n",
    "\n",
    "    # Calculating Average Absolute Brain Waves\n",
    "    df_avg_bw = df_records.drop(columns=['Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10', 'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10', 'Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10', 'Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8', 'Gamma_TP10'])\n",
    "    old_alpha_value = (df_records['Alpha_TP9'] + df_records['Alpha_AF7'] + df_records['Alpha_AF8'] + df_records['Alpha_TP10'])/4\n",
    "    old_beta_value = (df_records['Beta_TP9'] + df_records['Beta_AF7'] + df_records['Beta_AF8'] + df_records['Beta_TP10'])/4\n",
    "    old_delta_value = (df_records['Delta_TP9'] + df_records['Delta_AF7'] + df_records['Delta_AF8'] + df_records['Delta_TP10'])/4\n",
    "    old_gamma_value = (df_records['Gamma_TP9'] + df_records['Gamma_AF7'] + df_records['Gamma_AF8'] + df_records['Gamma_TP10'])/4\n",
    "    old_theta_value = (df_records['Theta_TP9'] + df_records['Theta_AF7'] + df_records['Theta_AF8'] + df_records['Theta_TP10'])/4\n",
    "\n",
    "    # Converting in new range\n",
    "    df_avg_bw['Alpha_Avg'] = (((old_alpha_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Beta_Avg'] = (((old_beta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Delta_Avg'] = (((old_delta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Gamma_Avg'] = (((old_gamma_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Theta_Avg'] = (((old_theta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    \n",
    "    # Calculating first ratio: Beta / (Alpha + Theta) --> task difficulty indicator + task engagement\n",
    "    df_avg_bw['First_Ratio'] = df_avg_bw['Beta_Avg'] / (df_avg_bw['Alpha_Avg'] + df_avg_bw['Theta_Avg'])\n",
    "        \n",
    "    # Calculating second ratio: Theta / (Alpha + Beta) --> task difficulty indicator\n",
    "    df_avg_bw['Second_Ratio'] = df_avg_bw['Theta_Avg'] / (df_avg_bw['Alpha_Avg'] + df_avg_bw['Beta_Avg'])\n",
    "\n",
    "    return df_avg_bw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Splitting data based on markers\n",
    "def split_data(df, df_markers):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    sections = []\n",
    "    \n",
    "    # Splitting the data and visualizing them separately\n",
    "    prev_timestamp = \"null\"\n",
    "    markers_timestamps = df_markers['TimeStamp'].tolist()\n",
    "    for timestamp in markers_timestamps:\n",
    "        \n",
    "        # Taking different actions for the dataframe splitting\n",
    "        if prev_timestamp != \"null\":\n",
    "            section = df[\n",
    "                df['TimeStamp'] > prev_timestamp\n",
    "            ]\n",
    "            section = section[\n",
    "                section['TimeStamp'] <= timestamp\n",
    "            ]\n",
    "            \n",
    "            sections.append(section)\n",
    "            i=i+1\n",
    "            \n",
    "        prev_timestamp = timestamp\n",
    "\n",
    "    # Visualizing the last part of the experiment\n",
    "    section = df[\n",
    "        df['TimeStamp'] > prev_timestamp\n",
    "    ]\n",
    "    sections.append(section)\n",
    "    \n",
    "    # Returns 6 sections: (baseline + scenario) x3\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Normalizing the data based on the baseline\n",
    "def normalize_data(sections):\n",
    "    \n",
    "    # Declaring variables for the method execution\n",
    "    h = 0\n",
    "    total_lines = 0\n",
    "    total_usable_lines = 0\n",
    "    frequency_columns = ['Alpha_Avg', 'Beta_Avg', 'Delta_Avg', 'Gamma_Avg', 'Theta_Avg']\n",
    "    new_sections = []\n",
    "    \n",
    "    # Iterating through the 3 baseline-experiment sections\n",
    "    for i in range(0,6,2):\n",
    "            \n",
    "        # Defining variables for execution\n",
    "        df_baseline = sections[i]\n",
    "        df_experiment = sections[i+1]\n",
    "        \n",
    "        # Extracting the last minute of recording \n",
    "        baseline_last_timestamp = df_baseline.iloc[-1]['TimeStamp']\n",
    "        baseline_start = baseline_last_timestamp - pd.Timedelta(minutes=1)        \n",
    "        df_baseline_min = df_baseline[df_baseline['TimeStamp'] >= baseline_start]\n",
    "        \n",
    "        # Calculating frequency averages as baseline\n",
    "        baseline_frequencies = []\n",
    "        print(\"Frequency Mean for scenario \" +str(h)+\":\")\n",
    "        for j in range(0,5):\n",
    "            baseline_frequencies.append(df_baseline_min[frequency_columns[j]].mean())\n",
    "            print(\"-- \" + frequency_columns[j] + \": \" +('%.2f' % (baseline_frequencies[j],)).rstrip('0').rstrip('.'))\n",
    "        print()\n",
    "            \n",
    "        # Subtracting baseline from experiment data\n",
    "        df_experiment_baseline = df_experiment.copy()\n",
    "        for k in range(0,5):\n",
    "            # df_experiment_baseline[frequency_columns[k]] = df_experiment[frequency_columns[k]] - baseline_frequencies[k]\n",
    "            df_experiment_baseline[frequency_columns[k]] = df_experiment[frequency_columns[k]]\n",
    "                \n",
    "        # Storing the elaborated sections\n",
    "        new_sections.append(df_experiment_baseline)\n",
    "        h = h + 1\n",
    "        \n",
    "    return new_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Create windows\n",
    "def split_in_windows(sections):\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END: Visualizing the data for the given simple sections\n",
    "def visualize_simple_plot(sections, extra_title, labels):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    \n",
    "    # Visualizing all the sections\n",
    "    for section in sections:\n",
    "        \n",
    "        # Defining variables used in method\n",
    "        df = section\n",
    "        title = labels[i]\n",
    "        \n",
    "        # Saving data in ColumnDataSource\n",
    "        data = {'TimeStamp': np.array(df['TimeStamp'], dtype='i8').view('datetime64[ms]').tolist(),\n",
    "                'Alpha': list(df['Alpha_Avg']),\n",
    "                'Beta': list(df['Beta_Avg']),\n",
    "                'Delta': list(df['Delta_Avg']),\n",
    "                'Gamma': list(df['Gamma_Avg']), \n",
    "                'Theta': list(df['Theta_Avg']),\n",
    "                'TimeStamp_tooltip': [x.strftime(\"%Y-%m-%d %H:%M:%S\") for x in df['TimeStamp']]\n",
    "                }\n",
    "        source = ColumnDataSource(data=data)\n",
    "\n",
    "        # Calculating the graph ranges\n",
    "        smallest = min_range\n",
    "        largest = max_range\n",
    "        smallest -= 5\n",
    "        largest += 5\n",
    "\n",
    "        # Plotting the data\n",
    "        p = figure(x_range=(min(data['TimeStamp']), max(data['TimeStamp'])), y_range=(smallest, largest), plot_width=1500, plot_height=600, title=extra_title+\": Plot of \"+title)\n",
    "        p.line(x='TimeStamp', y='Alpha', source=source, color=\"#3DB3FE\", line_width=2, legend=dict(value=\"Alpha\"))\n",
    "        p.line(x='TimeStamp', y='Beta', source=source, color=\"#38A967\", line_width=2, legend=dict(value=\"Beta\"))\n",
    "        p.line(x='TimeStamp', y='Delta', source=source, color=\"#C93030\", line_width=2, legend=dict(value=\"Delta\"))\n",
    "        p.line(x='TimeStamp', y='Gamma', source=source, color=\"#F1A219\", line_width=2, legend=dict(value=\"Gamma\"))\n",
    "        p.line(x='TimeStamp', y='Theta', source=source, color=\"#A822F3\", line_width=2, legend=dict(value=\"Theta\"))\n",
    "\n",
    "        # Adding hover and other visualization tools\n",
    "        hover = HoverTool()\n",
    "        hover.tooltips=[\n",
    "            (\"Value\", \"$y\"),\n",
    "            (\"Timestamp\", \"@TimeStamp_tooltip\")\n",
    "        ]\n",
    "        p.add_tools(hover)\n",
    "        p.add_layout(Title(text=\"TimeStamp\", align=\"center\"), \"below\")\n",
    "        p.add_layout(Title(text=\"Frequency\", align=\"center\"), \"left\")\n",
    "        p.xaxis.major_label_orientation = np.pi / 4\n",
    "        p.legend.location = 'top_right'\n",
    "        \n",
    "        show(p)\n",
    "        i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END: Visualizing the data for the given complex sections\n",
    "def visualize_complex_plot(sections, extra_title, labels):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    \n",
    "    # Visualizing all the sections\n",
    "    for section in sections:\n",
    "        \n",
    "        # Defining variables used in method\n",
    "        df = section\n",
    "        title = labels[i]\n",
    "        \n",
    "        # Saving data in ColumnDataSource\n",
    "        data = {'TimeStamp': np.array(df['TimeStamp'], dtype='i8').view('datetime64[ms]').tolist(),\n",
    "                'First_Ratio': list(df['First_Ratio']),\n",
    "                'Second_Ratio': list(df['Second_Ratio']),\n",
    "                'TimeStamp_tooltip': [x.strftime(\"%Y-%m-%d %H:%M:%S\") for x in df['TimeStamp']],\n",
    "                'Stress_Level': list (df['First_Ratio'] + df['Second_Ratio'])\n",
    "                }\n",
    "        source = ColumnDataSource(data=data)\n",
    "        \n",
    "        # Figures configuration\n",
    "        x_min = min(data['TimeStamp'])\n",
    "        x_max = max(data['TimeStamp'])\n",
    "        p_smallest = 0.2\n",
    "        p_largest = 0.8\n",
    "        p2_smallest = 0.8\n",
    "        p2_largest = 1.2\n",
    "        plot_width = 1500\n",
    "        plot_height = 400\n",
    "\n",
    "        # Plotting the data\n",
    "        p = figure(x_range=(x_min, x_max), y_range=(p_smallest, p_largest), plot_width=plot_width, plot_height=plot_height, title=extra_title+\": Plot of \"+title)\n",
    "        p.line(x='TimeStamp', y='First_Ratio', source=source, color=\"#f1df19\", line_width=2, legend=dict(value=\"First_Ratio\"))\n",
    "        p.line(x='TimeStamp', y='Second_Ratio', source=source, color=\"#f15319\", line_width=2, legend=dict(value=\"Second_Ratio\"))\n",
    "        \n",
    "        # Adding hover and other visualization tools\n",
    "        hover = HoverTool()\n",
    "        hover.tooltips=[\n",
    "            (\"Value\", \"$y\"),\n",
    "            (\"Timestamp\", \"@TimeStamp_tooltip\")\n",
    "        ]\n",
    "        p.add_tools(hover)\n",
    "        p.add_layout(Title(text=\"TimeStamp\", align=\"center\"), \"below\")\n",
    "        p.add_layout(Title(text=\"Frequency\", align=\"center\"), \"left\")\n",
    "        p.xaxis.major_label_orientation = np.pi / 4\n",
    "        p.legend.location = 'top_right'\n",
    "        \n",
    "        # Plotting the data\n",
    "        p2 = figure(x_range=(x_min, x_max), y_range=(p2_smallest, p2_largest), plot_width=plot_width, plot_height=plot_height, title=extra_title+\": Stress level of \"+title)\n",
    "        p2.line(x='TimeStamp', y='Stress_Level', source=source, color=\"green\", line_width=2, legend=dict(value=\"Stress_Level\"))\n",
    "        \n",
    "        # Visualize the plots and increment the iterator\n",
    "        show(column(p, p2))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Participant 01 ====\n",
      "2139/2157 usable lines \n",
      "Total usable lines for this participant is 99.17% - threshold: 8\n",
      "\n",
      "Frequency Mean for scenario 0:\n",
      "-- Alpha_Avg: 65.97\n",
      "-- Beta_Avg: 64.79\n",
      "-- Delta_Avg: 44.31\n",
      "-- Gamma_Avg: 52.36\n",
      "-- Theta_Avg: 49.35\n",
      "\n",
      "Frequency Mean for scenario 1:\n",
      "-- Alpha_Avg: 61.54\n",
      "-- Beta_Avg: 53.19\n",
      "-- Delta_Avg: 43.4\n",
      "-- Gamma_Avg: 42.11\n",
      "-- Theta_Avg: 46.55\n",
      "\n",
      "Frequency Mean for scenario 2:\n",
      "-- Alpha_Avg: 64.85\n",
      "-- Beta_Avg: 63.67\n",
      "-- Delta_Avg: 46.83\n",
      "-- Gamma_Avg: 50.75\n",
      "-- Theta_Avg: 50.11\n",
      "\n",
      "\n",
      "\n",
      "==== Participant 02 ====\n",
      "1535/1682 usable lines \n",
      "Total usable lines for this participant is 91.26% - threshold: 8\n",
      "\n",
      "Frequency Mean for scenario 0:\n",
      "-- Alpha_Avg: 75.1\n",
      "-- Beta_Avg: 65.12\n",
      "-- Delta_Avg: 67.44\n",
      "-- Gamma_Avg: 47.18\n",
      "-- Theta_Avg: 60.88\n",
      "\n",
      "Frequency Mean for scenario 1:\n",
      "-- Alpha_Avg: 89.92\n",
      "-- Beta_Avg: 76.91\n",
      "-- Delta_Avg: 88.87\n",
      "-- Gamma_Avg: 59.62\n",
      "-- Theta_Avg: 80.9\n",
      "\n",
      "Frequency Mean for scenario 2:\n",
      "-- Alpha_Avg: 83.6\n",
      "-- Beta_Avg: 76.57\n",
      "-- Delta_Avg: 78.24\n",
      "-- Gamma_Avg: 83.72\n",
      "-- Theta_Avg: 67.49\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------Main Method-------------------------------------------\n",
    "\n",
    "# TODO change it so that the algorithm takes this as input\n",
    "#participants = ['02']\n",
    "participants = ['01', '02']\n",
    "\n",
    "for participant in participants:\n",
    "    print(\"==== Participant \"+participant+\" ====\")\n",
    "    execute_class(participant)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
