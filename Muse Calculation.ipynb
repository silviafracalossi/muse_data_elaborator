{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muse Data Elaborator\n",
    "\n",
    "#### TODO:\n",
    "1. (done) Data Recording\n",
    "    1. (done) Choose the App\n",
    "    1. (done) Download the data\n",
    "1. Data Cleaning\n",
    "    1. (done) Remove noise\n",
    "    1. Remove invalid parts: sensor does not work -> remove that line\n",
    "1. Feature Extraction\n",
    "    1. (done) Calculation of features (five brain wave frequency bands)\n",
    "    1. (done) Normalize data using the baseline.\n",
    "1. \"Machine Learning\"\n",
    "    1. Split data. (window of even 2 seconds; 5-60 seconds)\n",
    "    1. Calculate the stress level.\n",
    "    1. Label data.\n",
    "1. (done) Data Visualization\n",
    "\n",
    "#### TODO from notes:\n",
    "1. windows of 10 seconds each; mean of the values\n",
    "1. scenario ranking per participant (stress level)\n",
    "1. sum the number of blinks and jaws, in experiment and in baseline\n",
    "1. scenario ranking per participant (blinks and jaws)\n",
    "\n",
    "1. restructure all the texts in the correct way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "##### Waves information\n",
    "1. Alpha:\n",
    "    - increases when a person is relaxed (the lower the busier)\n",
    "    - blocked in task engagement\n",
    "    \n",
    "    \n",
    "1. Beta:\n",
    "    - increases in task engagement\n",
    "    \n",
    "    \n",
    "1. Theta:\n",
    "    - increases in demand and working memory load\n",
    "    - sensitive to data difficulty\n",
    "    - suppressed in task engagement\n",
    "    \n",
    "    \n",
    "1. Delta:\n",
    "    - sensitive to data difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show, output_file, save, curdoc\n",
    "from bokeh.models import ColumnDataSource, HoverTool, NumeralTickFormatter, Title\n",
    "from bokeh.models.widgets import Select\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from datetime import datetime as dt\n",
    "from math import pi, sqrt\n",
    "import os\n",
    "\n",
    "# Scenarios Titles\n",
    "experiment_labels = ['scenario 1', 'scenario 2', 'scenario 3']\n",
    "all_scenario_labels = ['fishes 1', 'scenario 1', 'fishes 2', 'scenario 2', 'fishes 3', 'scenario 3']\n",
    "\n",
    "# Ranges for plots\n",
    "min_range = 200\n",
    "max_range = -100\n",
    "\n",
    "# Setting the threshold to have a good sensors signal - 4 HSI possible values: 1=Good, 2=Medium, 4=Bad\n",
    "hsi_threshold = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Calls all the algorithms in the right order\n",
    "def execute_class(participant_no):\n",
    "    \n",
    "    # Read the file\n",
    "    df = read_file(participant_no)\n",
    "    \n",
    "    # Clean the data and split it based on content\n",
    "    df_records, df_elements, df_markers = clean_data(df)\n",
    "\n",
    "    # Checking if the data returned is valid\n",
    "    if str(type(df_records)) != \"<class 'str'>\":\n",
    "        \n",
    "        # Calculating the frequencies using the correct range\n",
    "        df_prepared = extract_features(df_records)\n",
    "        #visualize_simple_plot([df_prepared], \"initial\", ['All'])\n",
    "        \n",
    "        # Split the data into baseline data and experiment data\n",
    "        sections = split_data(df_prepared, df_markers)\n",
    "        #visualize_simple_plot(sections, \"sections\", all_scenario_labels)\n",
    "        \n",
    "        # Normalize the experiment based on its baseline and the quality of data\n",
    "        normalized_sections = normalize_data(sections)\n",
    "        #visualize_simple_plot(normalized_sections, \"after_baseline_quality\", experiment_labels)\n",
    "        \n",
    "        # Calculating the stress indicators\n",
    "        stress_sections = calculate_stress(normalized_sections)\n",
    "        visualize_complex_plot(stress_sections, \"stress_sections\", experiment_labels)\n",
    "        \n",
    "        # Splitting data into comparable windows\n",
    "        window_sections = split_in_windows(stress_sections)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dato into dataframe\n",
    "def read_file(participant_no):\n",
    "    __file__ = participant_no + '.csv'\n",
    "    my_absolute_dirpath = os.path.abspath(os.path.dirname(__file__))\n",
    "    file_path = my_absolute_dirpath+\"\\\\aData\\\\\"+__file__\n",
    "    df = pd.read_csv(file_path, sep=\",\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removes useless columns and checks the correctness\n",
    "def clean_data(df):\n",
    "    # Removing useless columns and formatting\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'], errors='coerce')\n",
    "    df_cleaned = df.drop(columns=['Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z', 'AUX_RIGHT', 'Battery'])\n",
    "\n",
    "    # Extracting the markers from the dataframe\n",
    "    df_markers = df_cleaned[df_cleaned['Elements'].str.contains('/Marker/', na=False)]\n",
    "    df_markers = df_markers.reset_index(drop=True)\n",
    "    df_markers = df_markers[['TimeStamp', 'Elements']]\n",
    "    \n",
    "    # Checking if the markers are correct - Markers are 7: 1x \"marker 5\", 3x \"marker 1\", 3x \"marker 2\"\n",
    "    markers_no = df_markers.shape[0]\n",
    "    marker_five_no = df_markers[df_markers['Elements'] == '/Marker/5'].shape[0]\n",
    "    marker_one_no = df_markers[df_markers['Elements'] == '/Marker/1'].shape[0]\n",
    "    marker_two_no = df_markers[df_markers['Elements'] == '/Marker/1'].shape[0]\n",
    "    if not (markers_no == 7 and marker_five_no == 1 and marker_one_no == 3 and marker_two_no == 3):\n",
    "        print(\"Markers are not of the desired number or type\")\n",
    "        return '', '', ''\n",
    "    \n",
    "    # Deleting all records before the initial marker timestamp (time spent positioning the sensor)\n",
    "    df_start_markers = df_markers[df_markers['Elements'] == '/Marker/5']\n",
    "    timestamp_start = df_start_markers['TimeStamp'].iloc[-1]\n",
    "    df_formatted = df_cleaned[df_cleaned['TimeStamp'] >= timestamp_start]\n",
    "    \n",
    "    # Removing marker 5 from all dataframes\n",
    "    df_markers = df_markers.iloc[1:]\n",
    "    df_formatted = df_formatted.iloc[1:]\n",
    "\n",
    "    # Extracting the elements - markers, blinks, clinches\n",
    "    df_elements = df_formatted[df_formatted['Elements'].str.contains('/', na=False)]\n",
    "    df_elements = df_elements[['TimeStamp', 'Elements']]\n",
    "    df_elements = df_elements.dropna()\n",
    "    df_elements = df_elements.reset_index(drop=True)\n",
    "\n",
    "    # Extracting the records with the HeadBandOn\n",
    "    df_records = df_formatted[df_formatted['HeadBandOn'] == 1]\n",
    "    df_records = df_records.drop(columns=['Elements'])\n",
    "    df_records = df_records.reset_index(drop=True)\n",
    "    \n",
    "    return df_records, df_elements, df_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transforming and extracting data, including data split and normalization\n",
    "def extract_features(df_records):\n",
    "    \n",
    "    # Settings to change the data range\n",
    "    old_range_max = 3\n",
    "    old_range_min = -3\n",
    "    old_range = (old_range_max - old_range_min) \n",
    "    new_range_max = 200\n",
    "    new_range_min = -100\n",
    "    new_range = (new_range_max - new_range_min)\n",
    "\n",
    "    # Calculating Average Absolute Brain Waves\n",
    "    df_avg_bw = df_records.drop(columns=['Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10', 'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10', 'Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10', 'Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8', 'Gamma_TP10'])\n",
    "    old_alpha_value = (df_records['Alpha_TP9'] + df_records['Alpha_AF7'] + df_records['Alpha_AF8'] + df_records['Alpha_TP10'])/4\n",
    "    old_beta_value = (df_records['Beta_TP9'] + df_records['Beta_AF7'] + df_records['Beta_AF8'] + df_records['Beta_TP10'])/4\n",
    "    old_delta_value = (df_records['Delta_TP9'] + df_records['Delta_AF7'] + df_records['Delta_AF8'] + df_records['Delta_TP10'])/4\n",
    "    old_gamma_value = (df_records['Gamma_TP9'] + df_records['Gamma_AF7'] + df_records['Gamma_AF8'] + df_records['Gamma_TP10'])/4\n",
    "    old_theta_value = (df_records['Theta_TP9'] + df_records['Theta_AF7'] + df_records['Theta_AF8'] + df_records['Theta_TP10'])/4\n",
    "\n",
    "    # Converting in new range\n",
    "    df_avg_bw['Alpha_Avg'] = (((old_alpha_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Beta_Avg'] = (((old_beta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Delta_Avg'] = (((old_delta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Gamma_Avg'] = (((old_gamma_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    df_avg_bw['Theta_Avg'] = (((old_theta_value - old_range_min) * new_range) / old_range) + new_range_min\n",
    "    \n",
    "    return df_avg_bw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Splitting data based on markers\n",
    "def split_data(df, df_markers):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    sections = []\n",
    "    \n",
    "    # Splitting the data and visualizing them separately\n",
    "    prev_timestamp = \"null\"\n",
    "    markers_timestamps = df_markers['TimeStamp'].tolist()\n",
    "    for timestamp in markers_timestamps:\n",
    "        \n",
    "        # Taking different actions for the dataframe splitting\n",
    "        if prev_timestamp != \"null\":\n",
    "            section = df[\n",
    "                df['TimeStamp'] > prev_timestamp\n",
    "            ]\n",
    "            section = section[\n",
    "                section['TimeStamp'] <= timestamp\n",
    "            ]\n",
    "            \n",
    "            sections.append(section)\n",
    "            i=i+1\n",
    "            \n",
    "        prev_timestamp = timestamp\n",
    "\n",
    "    # Visualizing the last part of the experiment\n",
    "    section = df[\n",
    "        df['TimeStamp'] > prev_timestamp\n",
    "    ]\n",
    "    sections.append(section)\n",
    "    \n",
    "    # Returns 6 sections: (baseline + scenario) x3\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Normalizing the data based on the baseline\n",
    "def normalize_data(sections):\n",
    "    \n",
    "    # Min and Max range for plot\n",
    "    global min_range\n",
    "    global max_range\n",
    "        \n",
    "    # Retriving threshold for quality of data\n",
    "    global hsi_threshold\n",
    "    \n",
    "    # Declaring variables for the method execution\n",
    "    total_lines = 0\n",
    "    total_usable_lines = 0\n",
    "    frequency_columns = ['Alpha_Avg', 'Beta_Avg', 'Delta_Avg', 'Gamma_Avg', 'Theta_Avg']\n",
    "    \n",
    "    # Declaring returning variables\n",
    "    new_sections = []\n",
    "    \n",
    "    # Iterating through the 3 baseline-experiment sections\n",
    "    for i in range(0,6,2):\n",
    "            \n",
    "        # Baseline - Extracting the last minute of recording \n",
    "        df_baseline = sections[i]\n",
    "        baseline_last_timestamp = df_baseline.iloc[-1]['TimeStamp']\n",
    "        baseline_start = baseline_last_timestamp - pd.Timedelta(minutes=1)        \n",
    "        df_baseline_min = df_baseline[df_baseline['TimeStamp'] >= baseline_start]\n",
    "        \n",
    "        # Baseline - Removing low quality data\n",
    "        df_baseline_min['Sensor_Quality'] = df_baseline_min['HSI_TP9'] + df_baseline_min['HSI_AF7'] + df_baseline_min['HSI_AF8'] + df_baseline_min['HSI_TP10']\n",
    "        df_baseline_min_cleaned = df_baseline_min[df_baseline_min['Sensor_Quality'] <= hsi_threshold]\n",
    "        \n",
    "        # Baseline - Calculating frequencies average as baseline\n",
    "        baseline_frequencies = []\n",
    "        print(\"Frequency Mean for scenario \" +str(get_scenario_no(i))+\":\")\n",
    "        for j in range(0,5):\n",
    "            baseline_frequencies.append(df_baseline_min_cleaned[frequency_columns[j]].mean())\n",
    "            print(\"-- \" + frequency_columns[j] + \": \" +('%.2f' % (baseline_frequencies[j],)).rstrip('0').rstrip('.'))\n",
    "        \n",
    "        # Experiment - Removing low quality data\n",
    "        df_experiment = sections[i+1]\n",
    "        df_experiment['Sensor_Quality'] = df_experiment['HSI_TP9'] + df_experiment['HSI_AF7'] + df_experiment['HSI_AF8'] + df_experiment['HSI_TP10']\n",
    "        df_experiment_cleaned = df_experiment[df_experiment['Sensor_Quality'] <= hsi_threshold]\n",
    "        \n",
    "        # Experiment - Defining the data quality\n",
    "        lines = df_experiment.shape[0]\n",
    "        usable_lines = df_experiment_cleaned.shape[0]\n",
    "        total_lines = total_lines + lines\n",
    "        total_usable_lines = total_usable_lines + usable_lines\n",
    "        print(str(usable_lines) + \"/\" + str(lines) + \" usable lines for scenario \" +str(get_scenario_no(i)))\n",
    "        print()\n",
    "        \n",
    "        # Removing baseline from experiment\n",
    "        df_experiment_baseline = df_experiment_cleaned.copy()\n",
    "        for k in range(0,5):\n",
    "        #    df_experiment_baseline[frequency_columns[k]] = df_experiment_cleaned[frequency_columns[k]] - baseline_frequencies[k]\n",
    "            df_experiment_baseline[frequency_columns[k]] = df_experiment_cleaned[frequency_columns[k]]\n",
    "            \n",
    "        # Storing the min and max range of plot\n",
    "        for wave in frequency_columns:\n",
    "            this_min = min(df_experiment_baseline[wave])\n",
    "            this_max = max(df_experiment_cleaned[wave])\n",
    "            if min_range > this_min:\n",
    "                min_range = this_min\n",
    "            if max_range < this_max:\n",
    "                max_range = this_max\n",
    "        \n",
    "        # Storing the elaborated sections\n",
    "        new_sections.append(df_experiment_baseline)\n",
    "        \n",
    "    # Printing the survey data quality\n",
    "    print(\"Total usable lines for this participant is \"+('%.2f' % (100*total_usable_lines/total_lines,)).rstrip('0').rstrip('.')+\n",
    "          \"% - threshold: \"+str(hsi_threshold))\n",
    "\n",
    "    return new_sections\n",
    "\n",
    "# Returns the scenario number based on the iterator of method \"normalize_data\"\n",
    "def get_scenario_no(i):\n",
    "    if i == 0:\n",
    "        return 1\n",
    "    elif i == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Define stress levels\n",
    "def calculate_stress(sections):\n",
    "    \n",
    "    # Min and Max range for plot\n",
    "    global min_range\n",
    "    global max_range\n",
    "    \n",
    "    for section_df in sections:\n",
    "        \n",
    "        # Calculating first ratio: Beta / (Alpha + Theta) --> task difficulty indicator + task engagement\n",
    "        section_df['First_Ratio'] = section_df['Beta_Avg'] / (section_df['Alpha_Avg'] + section_df['Theta_Avg'])\n",
    "        \n",
    "        # Calculating second ratio: Theta / (Alpha + Beta) --> task difficulty indicator\n",
    "        section_df['Second_Ratio'] = section_df['Theta_Avg'] / (section_df['Alpha_Avg'] + section_df['Beta_Avg'])\n",
    "        \n",
    "        # Calculating the max-min range for plot\n",
    "        for ratio in ['First_Ratio', 'Second_Ratio']:\n",
    "            this_min = min(section_df[ratio])\n",
    "            this_max = max(section_df[ratio])\n",
    "            if min_range > this_min:\n",
    "                min_range = this_min\n",
    "            if max_range < this_max:\n",
    "                max_range = this_max\n",
    "        \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Create windows\n",
    "def split_in_windows(sections):\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END: Visualizing the data for the given simple sections\n",
    "def visualize_simple_plot(sections, extra_title, labels):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    \n",
    "    # Visualizing all the sections\n",
    "    for section in sections:\n",
    "        \n",
    "        # Defining variables used in method\n",
    "        df = section\n",
    "        title = labels[i]\n",
    "        \n",
    "        # Saving data in ColumnDataSource\n",
    "        data = {'TimeStamp': np.array(df['TimeStamp'], dtype='i8').view('datetime64[ms]').tolist(),\n",
    "                'Alpha': list(df['Alpha_Avg']),\n",
    "                'Beta': list(df['Beta_Avg']),\n",
    "                'Delta': list(df['Delta_Avg']),\n",
    "                'Gamma': list(df['Gamma_Avg']), \n",
    "                'Theta': list(df['Theta_Avg']),\n",
    "                'TimeStamp_tooltip': [x.strftime(\"%Y-%m-%d %H:%M:%S\") for x in df['TimeStamp']]\n",
    "                }\n",
    "        source = ColumnDataSource(data=data)\n",
    "\n",
    "        # Calculating the graph ranges\n",
    "        global min_range\n",
    "        global max_range\n",
    "        smallest = min_range\n",
    "        largest = max_range\n",
    "        smallest -= 5\n",
    "        largest += 5\n",
    "\n",
    "        # Plotting the data\n",
    "        p = figure(x_range=(min(data['TimeStamp']), max(data['TimeStamp'])), y_range=(smallest, largest), plot_width=1500, plot_height=600, title=extra_title+\": Plot of \"+title)\n",
    "        p.line(x='TimeStamp', y='Alpha', source=source, color=\"#3DB3FE\", line_width=2, legend=dict(value=\"Alpha\"))\n",
    "        p.line(x='TimeStamp', y='Beta', source=source, color=\"#38A967\", line_width=2, legend=dict(value=\"Beta\"))\n",
    "        p.line(x='TimeStamp', y='Delta', source=source, color=\"#C93030\", line_width=2, legend=dict(value=\"Delta\"))\n",
    "        p.line(x='TimeStamp', y='Gamma', source=source, color=\"#F1A219\", line_width=2, legend=dict(value=\"Gamma\"))\n",
    "        p.line(x='TimeStamp', y='Theta', source=source, color=\"#A822F3\", line_width=2, legend=dict(value=\"Theta\"))\n",
    "\n",
    "        # Adding hover and other visualization tools\n",
    "        hover = HoverTool()\n",
    "        hover.tooltips=[\n",
    "            (\"Value\", \"$y\"),\n",
    "            (\"Timestamp\", \"@TimeStamp_tooltip\")\n",
    "        ]\n",
    "        p.add_tools(hover)\n",
    "        p.add_layout(Title(text=\"TimeStamp\", align=\"center\"), \"below\")\n",
    "        p.add_layout(Title(text=\"Frequency\", align=\"center\"), \"left\")\n",
    "        p.xaxis.major_label_orientation = np.pi / 4\n",
    "        p.legend.location = 'top_right'\n",
    "        \n",
    "        show(p)\n",
    "        i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END: Visualizing the data for the given complex sections\n",
    "def visualize_complex_plot(sections, extra_title, labels):\n",
    "    \n",
    "    # Setting initial variable\n",
    "    i = 0\n",
    "    \n",
    "    # Visualizing all the sections\n",
    "    for section in sections:\n",
    "        \n",
    "        # Defining variables used in method\n",
    "        df = section\n",
    "        title = labels[i]\n",
    "        \n",
    "        # Saving data in ColumnDataSource\n",
    "        data = {'TimeStamp': np.array(df['TimeStamp'], dtype='i8').view('datetime64[ms]').tolist(),\n",
    "                'First_Ratio': list(df['First_Ratio']),\n",
    "                'Second_Ratio': list(df['Second_Ratio']),\n",
    "                'TimeStamp_tooltip': [x.strftime(\"%Y-%m-%d %H:%M:%S\") for x in df['TimeStamp']],\n",
    "                'Stress_Level': list (df['First_Ratio'] + df['Second_Ratio'])\n",
    "                }\n",
    "        source = ColumnDataSource(data=data)\n",
    "        \n",
    "        # Figures configuration\n",
    "        x_min = min(data['TimeStamp'])\n",
    "        x_max = max(data['TimeStamp'])\n",
    "        p_smallest = 0.2\n",
    "        p_largest = 0.8\n",
    "        p2_smallest = 0.4\n",
    "        p2_largest = 1.6\n",
    "        plot_width = 1500\n",
    "        plot_height = 400\n",
    "\n",
    "        # Plotting the data\n",
    "        p = figure(x_range=(x_min, x_max), y_range=(p_smallest, p_largest), plot_width=plot_width, plot_height=plot_height, title=extra_title+\": Plot of \"+title)\n",
    "        p.line(x='TimeStamp', y='First_Ratio', source=source, color=\"#f1df19\", line_width=2, legend=dict(value=\"First_Ratio\"))\n",
    "        p.line(x='TimeStamp', y='Second_Ratio', source=source, color=\"#f15319\", line_width=2, legend=dict(value=\"Second_Ratio\"))\n",
    "        \n",
    "        # Adding hover and other visualization tools\n",
    "        hover = HoverTool()\n",
    "        hover.tooltips=[\n",
    "            (\"Value\", \"$y\"),\n",
    "            (\"Timestamp\", \"@TimeStamp_tooltip\")\n",
    "        ]\n",
    "        p.add_tools(hover)\n",
    "        p.add_layout(Title(text=\"TimeStamp\", align=\"center\"), \"below\")\n",
    "        p.add_layout(Title(text=\"Frequency\", align=\"center\"), \"left\")\n",
    "        p.xaxis.major_label_orientation = np.pi / 4\n",
    "        p.legend.location = 'top_right'\n",
    "        \n",
    "        # Plotting the data\n",
    "        p2 = figure(x_range=(x_min, x_max), y_range=(p2_smallest, p2_largest), plot_width=plot_width, plot_height=plot_height, title=extra_title+\": Stress level of \"+title)\n",
    "        p2.line(x='TimeStamp', y='Stress_Level', source=source, color=\"green\", line_width=2, legend=dict(value=\"Stress_Level\"))\n",
    "        \n",
    "        # Visualize the plots and increment the iterator\n",
    "        show(column(p, p2))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------Main Method-------------------------------------------\n",
    "\n",
    "# TODO change it so that the algorithm takes this as input\n",
    "participants = ['02']\n",
    "#participants = ['01', '02']\n",
    "\n",
    "for participant in participants:\n",
    "    print(\"===== Participant \"+participant+\" =====\")\n",
    "    execute_class(participant)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
